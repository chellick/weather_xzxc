{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from coords_parcer import get_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам нужно заполнить пустые NaN значения датафрейма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"srock8/23463.dat\", na_values=np.nan)\n",
    "upd_df = df.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upd_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При помощи класса из библиотеки sklearn избавляемся от nan значений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* температуру - 'Температура воздуха по сухому термометру'\n",
    "* осадки - 'Сумма осадков за период между сроками'\n",
    "* влажность - 'Относительная влажность воздуха'\n",
    "* скорость ветра -  'Средняя скорость ветра'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(upd_df.columns)\n",
    "columns.remove('Температура воздуха по сухому термометру')\n",
    "columns.remove('Сумма осадков за период между сроками')\n",
    "columns.remove('Относительная влажность воздуха')\n",
    "columns.remove('Средняя скорость ветра')\n",
    "\n",
    "columns.extend(['Температура воздуха по сухому термометру', \n",
    "                'Сумма осадков за период между сроками',\n",
    "                'Относительная влажность воздуха',\n",
    "                'Средняя скорость ветра'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = get_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_upd_df = upd_df.to_numpy(dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "tempreture_y = []\n",
    "precipitation_y = []\n",
    "humidity_y = []\n",
    "wind_y = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np_upd_df:\n",
    "    X.append(i[:-4])\n",
    "    tempreture_y.append(i[-4])\n",
    "    precipitation_y.append(i[-3])\n",
    "    humidity_y.append(i[-2])\n",
    "    wind_y.append(i[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "tempreture_y = np.array(tempreture_y)\n",
    "precipitation_y = np.array(precipitation_y)\n",
    "humidity_y = np.array(humidity_y)\n",
    "wind_y = np.array(wind_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp_train, X_temp_test, y_temp_train, y_temp_test = train_test_split(X, tempreture_y,\n",
    "                                                                        test_size=0.2,\n",
    "                                                                        random_state=10,\n",
    "                                                                        shuffle=True)\n",
    "\n",
    "X_precipitation_train, X_precipitation_test, y_precipitation_train, y_precipitation_test = train_test_split(X, precipitation_y,\n",
    "                                                                                                            test_size=0.2,\n",
    "                                                                                                            random_state=10,\n",
    "                                                                                                            shuffle=True)\n",
    "\n",
    "X_humidity_train, X_humidity_test, y_humidity_train, y_humidity_test = train_test_split(X, humidity_y,\n",
    "                                                                                        test_size=0.2,\n",
    "                                                                                        random_state=10,\n",
    "                                                                                        shuffle=True)\n",
    "\n",
    "X_wind_train, X_wind_test, y_wind_train, y_wind_test = train_test_split(X, wind_y,\n",
    "                                                                        test_size=0.2,\n",
    "                                                                        random_state=10,\n",
    "                                                                        shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    keras.layers.Input((86)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(86*3),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Dense(86*3),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "optim = tf.keras.optimizers.SGD()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_temp_train, y_temp_train,\n",
    "          batch_size=32,\n",
    "          epochs=20,\n",
    "          validation_split=0.1)\n",
    "loss = model.evaluate(X_temp_test, y_temp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(filepath='tf_models/tempreture_model_weights.h5')\n",
    "model.save(filepath='tf_models/tempreture_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    keras.layers.Input((86)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(86*3),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Dense(86*3),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "optim = tf.keras.optimizers.SGD()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error')\n",
    "\n",
    "\n",
    "model.fit(X_precipitation_train, y_precipitation_train,\n",
    "          batch_size=32,\n",
    "          epochs=20,\n",
    "          validation_split=0.1)\n",
    "loss = model.evaluate(X_precipitation_test, y_precipitation_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(filepath='tf_models/precipitation_model_weights.h5')\n",
    "model.save(filepath='tf_models/precipitation_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3419/3419 [==============================] - 6s 2ms/step - loss: 407333054185472.0000 - val_loss: 81562863403008.0000\n",
      "Epoch 2/20\n",
      "3419/3419 [==============================] - 5s 2ms/step - loss: 97221768904704.0000 - val_loss: 9875533.0000\n",
      "Epoch 3/20\n",
      "3419/3419 [==============================] - 5s 1ms/step - loss: 12953485049856.0000 - val_loss: 49.6454\n",
      "Epoch 4/20\n",
      "3419/3419 [==============================] - 5s 2ms/step - loss: 176173418020864.0000 - val_loss: 205073973248.0000\n",
      "Epoch 5/20\n",
      "3419/3419 [==============================] - 5s 1ms/step - loss: 23644759654400.0000 - val_loss: 84.7318\n",
      "Epoch 6/20\n",
      "3419/3419 [==============================] - 5s 1ms/step - loss: 40625596530688.0000 - val_loss: 3785.3066\n",
      "Epoch 7/20\n",
      "3419/3419 [==============================] - 5s 1ms/step - loss: 24657459675136.0000 - val_loss: 81.5835\n",
      "Epoch 8/20\n",
      "3419/3419 [==============================] - 5s 2ms/step - loss: 67271380697088.0000 - val_loss: 28.8656\n",
      "Epoch 9/20\n",
      "3419/3419 [==============================] - 5s 2ms/step - loss: 10363303100416.0000 - val_loss: 3.4552\n",
      "Epoch 10/20\n",
      "3419/3419 [==============================] - 5s 2ms/step - loss: 28265194455040.0000 - val_loss: 769.9879\n",
      "Epoch 11/20\n",
      "3419/3419 [==============================] - 5s 2ms/step - loss: 4.8935 - val_loss: 2.9054\n",
      "Epoch 12/20\n",
      "3419/3419 [==============================] - 5s 1ms/step - loss: 4.4649 - val_loss: 2.2363\n",
      "Epoch 13/20\n",
      "3419/3419 [==============================] - 5s 2ms/step - loss: 44481466335232.0000 - val_loss: 240.9046\n",
      "Epoch 14/20\n",
      "3419/3419 [==============================] - 5s 1ms/step - loss: 27592214183936.0000 - val_loss: 4.1011\n",
      "Epoch 15/20\n",
      "3419/3419 [==============================] - 5s 2ms/step - loss: 5.2187 - val_loss: 4.7663\n",
      "Epoch 16/20\n",
      "3419/3419 [==============================] - 5s 2ms/step - loss: 5.7972 - val_loss: 8.3910\n",
      "Epoch 17/20\n",
      "3419/3419 [==============================] - 5s 2ms/step - loss: 19226865696768.0000 - val_loss: 6.3197\n",
      "Epoch 18/20\n",
      "3419/3419 [==============================] - 5s 1ms/step - loss: 7841412284416.0000 - val_loss: 3.9039\n",
      "Epoch 19/20\n",
      "3419/3419 [==============================] - 5s 1ms/step - loss: 3.8141 - val_loss: 4.8521\n",
      "Epoch 20/20\n",
      "3419/3419 [==============================] - 5s 1ms/step - loss: 48035446915072.0000 - val_loss: 1.7489\n",
      "950/950 [==============================] - 1s 980us/step - loss: 1.7211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\GitHub\\weather_xzxc\\ven\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    keras.layers.Input((86)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(86*3),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Dense(86*3),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "optim = tf.keras.optimizers.SGD()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error')\n",
    "\n",
    "\n",
    "model.fit(X_humidity_train, y_humidity_train,\n",
    "          batch_size=32,\n",
    "          epochs=20,\n",
    "          validation_split=0.1)\n",
    "loss = model.evaluate(X_humidity_test, y_humidity_test)\n",
    "\n",
    "model.save_weights(filepath='tf_models/humidity_model_weights.h5')\n",
    "model.save(filepath='tf_models/humidity_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3419/3419 [==============================] - 6s 2ms/step - loss: 148415933579264.0000 - val_loss: 1952.9729\n",
      "Epoch 2/20\n",
      "3419/3419 [==============================] - 5s 1ms/step - loss: 5825898217472.0000 - val_loss: 129695.6719\n",
      "Epoch 3/20\n",
      "3419/3419 [==============================] - 5s 1ms/step - loss: 1516907397120.0000 - val_loss: 1833195392.0000\n",
      "Epoch 4/20\n",
      "3419/3419 [==============================] - 5s 1ms/step - loss: 469954560000.0000 - val_loss: 3055350272.0000\n",
      "Epoch 5/20\n",
      "3419/3419 [==============================] - 5s 1ms/step - loss: 128124018688.0000 - val_loss: 1365221760.0000\n",
      "Epoch 6/20\n",
      "3419/3419 [==============================] - 5s 1ms/step - loss: 59753734144.0000 - val_loss: 65.8694\n",
      "Epoch 7/20\n",
      "3419/3419 [==============================] - 5s 1ms/step - loss: 31601381376.0000 - val_loss: 77.6114\n",
      "Epoch 8/20\n",
      "3419/3419 [==============================] - 5s 1ms/step - loss: 1834647040.0000 - val_loss: 92.7615\n",
      "Epoch 9/20\n",
      "3419/3419 [==============================] - 5s 2ms/step - loss: 862881792.0000 - val_loss: 12.8057\n",
      "Epoch 10/20\n",
      "3419/3419 [==============================] - 5s 1ms/step - loss: 105986248.0000 - val_loss: 111058.1875\n",
      "Epoch 11/20\n",
      "3419/3419 [==============================] - 5s 1ms/step - loss: 1960936320.0000 - val_loss: 7.2634\n",
      "Epoch 12/20\n",
      "3419/3419 [==============================] - 5s 1ms/step - loss: 118078600.0000 - val_loss: 83.0792\n",
      "Epoch 13/20\n",
      "3419/3419 [==============================] - 5s 1ms/step - loss: 453098784.0000 - val_loss: 11.5950\n",
      "Epoch 14/20\n",
      "3419/3419 [==============================] - 5s 1ms/step - loss: 30450422.0000 - val_loss: 40.3954\n",
      "Epoch 15/20\n",
      "3419/3419 [==============================] - 5s 1ms/step - loss: 151000976.0000 - val_loss: 5.0078\n",
      "Epoch 16/20\n",
      "3419/3419 [==============================] - 5s 1ms/step - loss: 5.7449 - val_loss: 7.1996\n",
      "Epoch 17/20\n",
      "3419/3419 [==============================] - 5s 1ms/step - loss: 12561.4473 - val_loss: 15.0906\n",
      "Epoch 18/20\n",
      "3419/3419 [==============================] - 5s 1ms/step - loss: 987555.8125 - val_loss: 8.3774\n",
      "Epoch 19/20\n",
      "3419/3419 [==============================] - 5s 1ms/step - loss: 6.5325 - val_loss: 8.6244\n",
      "Epoch 20/20\n",
      "3419/3419 [==============================] - 5s 2ms/step - loss: 29367.3008 - val_loss: 5.2163\n",
      "950/950 [==============================] - 1s 965us/step - loss: 5.2980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\GitHub\\weather_xzxc\\ven\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    keras.layers.Input((86)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(86*3),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Dense(86*3),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "optim = tf.keras.optimizers.SGD()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error')\n",
    "\n",
    "\n",
    "model.fit(X_wind_train, y_wind_train,\n",
    "          batch_size=32,\n",
    "          epochs=20,\n",
    "          validation_split=0.1)\n",
    "loss = model.evaluate(X_wind_test, y_wind_test)\n",
    "\n",
    "model.save_weights(filepath='tf_models/wind_model_weights.h5')\n",
    "model.save(filepath='tf_models/wind_model.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ven",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
